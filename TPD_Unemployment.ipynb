{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "!pip install ipywidgets\n",
        "!pip install opendatasets ipyopenlayers pandas\n",
        "\n",
        "from ipyopenlayers import RasterTileLayer, ZoomSlider, Map\n",
        "from ipyleaflet import Map, Marker, MarkerCluster,Popup\n",
        "from ipywidgets import HTML\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from geopy.geocoders import Nominatim\n",
        "from shapely.geometry import Point\n",
        "import time\n",
        "import os\n",
        "import kagglehub\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "!pip install pyspark opendatasets kagglehub\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, substring, avg, when, lit, min as spark_min, max as spark_max\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"QOLDataProcessing\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "import kagglehub\n",
        "import zipfile\n",
        "\n",
        "# # !kaggle datasets download -d guslovesmath/us-pollution-data-200-to-2022 -p ./ --unzip\n",
        "# path = kagglehub.dataset_download(\"guslovesmath/us-pollution-data-200-to-2022\")\n",
        "# with zipfile.ZipFile(\"us-pollution-data-200-to-2022.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"data\")\n",
        "file_path = \"QOL.csv\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CGFZ6Sihmk2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44242dc-52ea-4de7-8b8b-dc3255bdeec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.7)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: ipyopenlayers in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.2.1)\n",
            "Requirement already satisfied: ipywidgets>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from ipyopenlayers) (8.1.7)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from ipyopenlayers) (5.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->ipyopenlayers) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->ipyopenlayers) (7.34.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->ipyopenlayers) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->ipyopenlayers) (3.0.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.2.13)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace, col\n",
        "from pyspark.sql.types import FloatType\n",
        "file_path = \"QOL.csv\"\n",
        "\n",
        "\n",
        "df = spark.read.option(\"header\", True).csv(file_path)\n",
        "# Select a quality of life indicator for marker coloring (e.g., Crime Rate)\n",
        "indicator = 'Unemployment'\n",
        "\n",
        "# Remove '%' and convert to float\n",
        "df = df.withColumn(indicator, regexp_replace(col(indicator), '%', '').cast(FloatType()))\n",
        "\n"
      ],
      "metadata": {
        "id": "c4Q40yZOYIwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "state_unemployment_avg = df.groupBy(\"LSTATE\").agg(mean(indicator).alias(\"avg_unemployment\"))\n",
        "state_unemployment_avg = state_unemployment_avg.withColumnRenamed(\"LSTATE\", \"state\")\n",
        "\n",
        "# Salvează în CSV\n",
        "state_unemployment_avg.write.csv('state_unemployment_avg.csv', header=True, mode='overwrite')\n",
        "\n",
        "# Selectăm coloanele necesare\n",
        "rankings_df = df.select(\"LSTATE\", \"NMCNTY\", indicator, \"countyhelper\")\n",
        "\n",
        "# Redenumim coloanele pentru claritate\n",
        "rankings_df = rankings_df.withColumnRenamed(\"LSTATE\", \"state\") \\\n",
        "                         .withColumnRenamed(\"NMCNTY\", \"county\") \\\n",
        "                         .withColumnRenamed(indicator, \"Unemployment\")\n",
        "\n",
        "# Calculăm valorile minime și maxime pentru scorul de ranking\n",
        "min_unemployment = rankings_df.agg(F.min(\"Unemployment\")).collect()[0][0]\n",
        "max_unemployment = rankings_df.agg(F.max(\"Unemployment\")).collect()[0][0]\n",
        "\n",
        "# Calculăm scorul de ranking\n",
        "rankings_df = rankings_df.withColumn(\"ranking\", 1 - ((F.col(\"Unemployment\") - min_unemployment) / (max_unemployment - min_unemployment)))\n",
        "\n",
        "# Salvăm rezultatul într-un fișier CSV\n",
        "rankings_df.write.csv(\"unemployment_rankings.csv\", header=True, mode=\"overwrite\")\n"
      ],
      "metadata": {
        "id": "p2vGmgR3tDgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up geolocator with increased timeout\n",
        "geolocator = Nominatim(user_agent=\"qof_map_app\", timeout=10)\n",
        "\n",
        "# Load cache if it exists\n",
        "cache_file = \"geocode_cache.pkl\"\n",
        "if os.path.exists(cache_file):\n",
        "    with open(cache_file, \"rb\") as f:\n",
        "        geocode_cache = pickle.load(f)\n",
        "else:\n",
        "    geocode_cache = {}\n",
        "\n",
        "# Create a dictionary to store locations not found\n",
        "not_found_cache = {}\n",
        "\n",
        "# Define geocoding function with caching\n",
        "def geocode_location(row):\n",
        "    row['county'] = row['county'].replace(' County', '')\n",
        "    row['county'] = row['county'].replace(' city', '')\n",
        "    row['county'] = row['county'].replace(' Census Area', '')\n",
        "    row['county'] = row['county'].replace('District of Columbia', 'Washington')\n",
        "    county_state = f\"{row['county']}, {row['state']}\"\n",
        "    if county_state in geocode_cache:\n",
        "        return geocode_cache[county_state]\n",
        "    if county_state in not_found_cache:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        if row['county'] == 'Not in a county':\n",
        "            # Geocode using only state\n",
        "            location = geolocator.geocode({\"state\": row['state'], \"country\": \"USA\"})\n",
        "            if location:\n",
        "                point = Point(location.longitude, location.latitude)\n",
        "                geocode_cache[county_state] = point\n",
        "                return point\n",
        "            else:\n",
        "                print(f\"Location not found for state: {row['state']}\")\n",
        "                not_found_cache[county_state] = None\n",
        "                return None\n",
        "        else:\n",
        "            # Geocode using county and state\n",
        "            location = geolocator.geocode({\"county\": row['county'], \"state\": row['state'], \"country\": \"USA\"})\n",
        "            if location:\n",
        "                point = Point(location.longitude, location.latitude)\n",
        "                geocode_cache[county_state] = point\n",
        "                return point\n",
        "            else:\n",
        "                print(f\"Location not found: {county_state}\")\n",
        "                # Attempt to geocode using only state\n",
        "                location2 = geolocator.geocode({\"state\": row['state'], \"country\": \"USA\"})\n",
        "                if location2:\n",
        "                    point = Point(location2.longitude, location2.latitude)\n",
        "                    geocode_cache[county_state] = point\n",
        "                    return point\n",
        "                else:\n",
        "                    not_found_cache[county_state] = None\n",
        "                return None\n",
        "    except Exception as e:\n",
        "        print(f\"Geocoding error for {county_state}: {e}\")\n",
        "        time.sleep(1)\n",
        "        return None\n",
        "\n",
        "# Apply geocoding with a progress bar\n",
        "aggregated_df_pd = rankings_df.toPandas()\n",
        "aggregated_df_pd['geometry'] = [geocode_location(row) for _, row in tqdm(aggregated_df_pd.iterrows(), total=len(aggregated_df_pd))]\n",
        "\n",
        "# Save cache for future use\n",
        "with open(cache_file, \"wb\") as f:\n",
        "    pickle.dump(geocode_cache, f)\n",
        "\n",
        "# Save not found cache for future reference\n",
        "not_found_cache_file = \"not_found_cache.pkl\"\n",
        "with open(not_found_cache_file, \"wb\") as f:\n",
        "    pickle.dump(not_found_cache, f)\n",
        "\n",
        "# Drop rows with missing geometry\n",
        "df = aggregated_df_pd.dropna(subset=['geometry'])\n",
        "\n",
        "# Create a GeoDataFrame\n",
        "gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")"
      ],
      "metadata": {
        "id": "CfXu5g_kkUlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7680991-412e-415c-c8af-673582fae653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▊        | 583/3134 [09:32<42:11,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Taylor, GA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 777/3134 [12:35<39:59,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Jones, GA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 943/3134 [15:18<36:12,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Spencer, KY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 1108/3134 [17:58<33:48,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Mitchell, GA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 1160/3134 [18:51<32:32,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Russell, KY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 1315/3134 [21:25<29:59,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: De Witt, IL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 1346/3134 [21:54<25:37,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Smith, TN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 1847/3134 [30:02<20:59,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Preston, WV\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 2022/3134 [32:54<18:17,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Cleveland, NC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 2035/3134 [33:09<18:28,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Montgomery, VA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 2250/3134 [36:37<15:03,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Franklin, VT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 2617/3134 [42:39<08:33,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Windsor, VT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 2794/3134 [45:37<08:07,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Richmond, NY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 2844/3134 [46:24<04:37,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Richmond, GA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 2897/3134 [47:16<04:01,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Bethel, AK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 2918/3134 [47:37<03:34,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: York, PA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 2987/3134 [48:44<02:26,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Monroe, NY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 3003/3134 [49:01<02:11,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Lake, IN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 3076/3134 [50:12<00:57,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Washington, DC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 3107/3134 [50:43<00:26,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Franklin, OH\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 3112/3134 [50:49<00:23,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Kings, NY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3134/3134 [51:13<00:00,  1.02it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.to_csv(\"qof_data_spark_geocode.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "rZnDMH_8l52e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Valoare minimă Unemployment:\", gdf[\"Unemployment\"].min())\n",
        "print(\"Valoare maximă Unemployment:\", gdf[\"Unemployment\"].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1H2lMdp5GYT",
        "outputId": "44791f95-1a3b-4949-c32a-04a3c77fc403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valoare minimă Unemployment: -1.0\n",
            "Valoare maximă Unemployment: 17.190000534057617\n"
          ]
        }
      ]
    }
  ]
}