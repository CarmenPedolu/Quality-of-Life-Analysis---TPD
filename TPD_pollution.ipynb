{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "!pip install ipywidgets\n",
        "!pip install opendatasets ipyopenlayers pandas\n",
        "\n",
        "from ipyopenlayers import RasterTileLayer, ZoomSlider, Map\n",
        "from ipyleaflet import Map, Marker, MarkerCluster,Popup\n",
        "from ipywidgets import HTML\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from geopy.geocoders import Nominatim\n",
        "from shapely.geometry import Point\n",
        "import time\n",
        "import os\n",
        "import kagglehub\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "!pip install pyspark opendatasets kagglehub\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, substring, avg, when, lit, min as spark_min, max as spark_max\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PollutionDataProcessing\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "import kagglehub\n",
        "import zipfile\n",
        "\n",
        "# # !kaggle datasets download -d guslovesmath/us-pollution-data-200-to-2022 -p ./ --unzip\n",
        "# path = kagglehub.dataset_download(\"guslovesmath/us-pollution-data-200-to-2022\")\n",
        "# with zipfile.ZipFile(\"us-pollution-data-200-to-2022.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"data\")\n",
        "file_path = \"pollution_2000_2023.csv\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CGFZ6Sihmk2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce463637-2f59-4078-b2da-61fb084e5f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.7)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: ipyopenlayers in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: ipywidgets>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from ipyopenlayers) (8.1.7)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from ipyopenlayers) (5.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->ipyopenlayers) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->ipyopenlayers) (7.34.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->ipyopenlayers) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->ipyopenlayers) (3.0.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.0->ipyopenlayers) (0.2.13)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"pollution_2000_2023.csv\"\n",
        "\n",
        "\n",
        "\n",
        "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(file_path)\n",
        "df.printSchema()\n",
        "df.select(\"Date\", \"State\", \"City\", \"NO2 1st Max Value\").show(5)\n",
        "\n",
        "def calculate_no2_aqi_spark():\n",
        "    return when(col(\"NO2 1st Max Value\") <= 53,  ((50 - 0) / (53 - 0)) * (col(\"NO2 1st Max Value\") - 0) + 0)\\\n",
        "        .when((col(\"NO2 1st Max Value\") <= 100), ((100 - 51) / (100 - 54)) * (col(\"NO2 1st Max Value\") - 54) + 51)\\\n",
        "        .when((col(\"NO2 1st Max Value\") <= 360), ((150 - 101) / (360 - 101)) * (col(\"NO2 1st Max Value\") - 101) + 101)\\\n",
        "        .when((col(\"NO2 1st Max Value\") <= 649), ((200 - 151) / (649 - 361)) * (col(\"NO2 1st Max Value\") - 361) + 151)\\\n",
        "        .when((col(\"NO2 1st Max Value\") <= 1249), ((300 - 201) / (1249 - 650)) * (col(\"NO2 1st Max Value\") - 650) + 201)\\\n",
        "        .otherwise(((500 - 301) / (2049 - 1250)) * (col(\"NO2 1st Max Value\") - 1250) + 301)\n",
        "\n",
        "df = df.withColumn(\"NO2 AQI\", calculate_no2_aqi_spark())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Q40yZOYIwf",
        "outputId": "a6df164d-7c1d-4c2e-dca9-c5448e286c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Address: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- County: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- O3 Mean: double (nullable = true)\n",
            " |-- O3 1st Max Value: double (nullable = true)\n",
            " |-- O3 1st Max Hour: integer (nullable = true)\n",
            " |-- O3 AQI: integer (nullable = true)\n",
            " |-- CO Mean: double (nullable = true)\n",
            " |-- CO 1st Max Value: double (nullable = true)\n",
            " |-- CO 1st Max Hour: integer (nullable = true)\n",
            " |-- CO AQI: double (nullable = true)\n",
            " |-- SO2 Mean: double (nullable = true)\n",
            " |-- SO2 1st Max Value: double (nullable = true)\n",
            " |-- SO2 1st Max Hour: integer (nullable = true)\n",
            " |-- SO2 AQI: double (nullable = true)\n",
            " |-- NO2 Mean: double (nullable = true)\n",
            " |-- NO2 1st Max Value: double (nullable = true)\n",
            " |-- NO2 1st Max Hour: integer (nullable = true)\n",
            " |-- NO2 AQI: integer (nullable = true)\n",
            "\n",
            "+----------+-------+-------+-----------------+\n",
            "|      Date|  State|   City|NO2 1st Max Value|\n",
            "+----------+-------+-------+-----------------+\n",
            "|2000-01-01|Arizona|Phoenix|             49.0|\n",
            "|2000-01-02|Arizona|Phoenix|             36.0|\n",
            "|2000-01-03|Arizona|Phoenix|             51.0|\n",
            "|2000-01-04|Arizona|Phoenix|             74.0|\n",
            "|2000-01-05|Arizona|Phoenix|             61.0|\n",
            "+----------+-------+-------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, substring, lit\n",
        "\n",
        "# Extragem anul și luna\n",
        "df = df.withColumn(\"Year\", substring(\"Date\", 1, 4).cast(\"int\"))\n",
        "df = df.withColumn(\"Month\", substring(\"Date\", 6, 2).cast(\"int\"))\n",
        "\n",
        "# Alegem coloanele relevante\n",
        "selected_columns = [\n",
        "    \"Date\", \"State\", \"County\", \"City\", \"O3 Mean\", \"O3 1st Max Value\", \"O3 AQI\",\n",
        "    \"CO Mean\", \"CO 1st Max Value\", \"CO AQI\",\n",
        "    \"SO2 Mean\", \"SO2 1st Max Value\", \"SO2 AQI\",\n",
        "    \"NO2 Mean\", \"NO2 1st Max Value\", \"NO2 AQI\", \"Year\", \"Month\"\n",
        "]\n",
        "filtered_df = df.select(*selected_columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "hpEApLsnb-S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wcs02OYaqpL",
        "outputId": "772ac346-d590-4d25-b597-dd951d12e795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(Date=datetime.date(2000, 1, 1), State='Arizona', County='Maricopa', City='Phoenix', O3 Mean=0.019765, O3 1st Max Value=0.04, O3 AQI=37, CO Mean=0.8789469999999999, CO 1st Max Value=2.2, CO AQI=25.0, SO2 Mean=3.0, SO2 1st Max Value=9.0, SO2 AQI=13.0, NO2 Mean=19.041667, NO2 1st Max Value=49.0, NO2 AQI=46.22641509433962, Year=2000, Month=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coloane de grupare\n",
        "group_cols_month = [\"Year\", \"Month\", \"State\", \"County\", \"City\"]\n",
        "group_cols_year = [\"Year\", \"State\", \"County\", \"City\"]\n",
        "\n",
        "# Coloane care vor fi agregate (exclude toate coloanele de grupare)\n",
        "agg_cols = [col for col in filtered_df.columns if col not in group_cols_month + [\"Date\"]]\n",
        "\n",
        "# Agregare pe lună\n",
        "agg_month = filtered_df.groupBy(*group_cols_month) \\\n",
        "    .agg(*[avg(col_name).alias(col_name) for col_name in agg_cols]) \\\n",
        "    .withColumn(\"Granularity\", lit(\"monthly\"))\n",
        "\n",
        "# Agregare pe an (Month = All)\n",
        "agg_year = filtered_df.groupBy(*group_cols_year) \\\n",
        "    .agg(*[avg(col_name).alias(col_name) for col_name in agg_cols]) \\\n",
        "    .withColumn(\"Month\", lit(None)) \\\n",
        "    .withColumn(\"Granularity\", lit(\"yearly\"))\n",
        "\n",
        "# Union corect\n",
        "aggregated_df = agg_month.unionByName(agg_year)\n"
      ],
      "metadata": {
        "id": "eBhq-wjxe6KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(agg_month.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvn4Jk6ye62W",
        "outputId": "afb5fb7a-822a-4407-ef86-b0422627a000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(Year=2000, Month=7, State='California', County='Sacramento', City='Arden-Arcade', O3 Mean=0.03446293548387097, O3 1st Max Value=0.05558064516129033, O3 AQI=69.48387096774194, CO Mean=0.17597754838709673, CO 1st Max Value=0.2806451612903226, CO AQI=3.0, SO2 Mean=1.93494964516129, SO2 1st Max Value=5.258064516129032, SO2 AQI=7.483870967741935, NO2 Mean=10.871969548387096, NO2 1st Max Value=17.967741935483872, NO2 AQI=16.950699939135724, Granularity='monthly')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Combinare\n",
        "aggregated_df = agg_month.unionByName(agg_year)\n",
        "\n",
        "# Ranking ca sumă AQI\n",
        "aggregated_df = aggregated_df.withColumn(\"Ranking\",\n",
        "    col(\"O3 AQI\") + col(\"CO AQI\") + col(\"SO2 AQI\") + col(\"NO2 AQI\")\n",
        ")\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import min, max\n",
        "\n",
        "w = Window.partitionBy(\"Year\", \"Month\")\n",
        "\n",
        "aggregated_df = aggregated_df.withColumn(\"min_rank\", spark_min(\"Ranking\").over(w)) \\\n",
        "    .withColumn(\"max_rank\", spark_max(\"Ranking\").over(w)) \\\n",
        "    .withColumn(\"ranking_final_value\", 1 - ((col(\"Ranking\") - col(\"min_rank\")) / (col(\"max_rank\") - col(\"min_rank\")))) \\\n",
        "    .drop(\"min_rank\", \"max_rank\")\n",
        "\n",
        "aggregated_df.write.mode(\"overwrite\").option(\"header\", True).csv(\"aggregated_pollution_data_spark.csv\")\n"
      ],
      "metadata": {
        "id": "cXqfSDWfZced"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_df_pd = aggregated_df.toPandas()\n",
        "aggregated_df_pd.to_csv('aggregated_pollution_data_spark_final_all.csv', index=False)"
      ],
      "metadata": {
        "id": "baLIOD_Dj3Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up geolocator with increased timeout\n",
        "geolocator = Nominatim(user_agent=\"pollution_map_app\", timeout=10)\n",
        "\n",
        "# Load cache if it exists\n",
        "cache_file = \"geocode_cache.pkl\"\n",
        "if os.path.exists(cache_file):\n",
        "    with open(cache_file, \"rb\") as f:\n",
        "        geocode_cache = pickle.load(f)\n",
        "else:\n",
        "    geocode_cache = {}\n",
        "\n",
        "# Create a dictionary to store locations not found\n",
        "not_found_cache = {}\n",
        "\n",
        "# Define geocoding function with caching\n",
        "def geocode_location(row):\n",
        "    city_state = f\"{row['City']}, {row['State']}\"\n",
        "    if city_state in geocode_cache:\n",
        "        return geocode_cache[city_state]\n",
        "    if city_state in not_found_cache:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        if row['City'] == 'Not in a city':\n",
        "            # Geocode using only state\n",
        "            location = geolocator.geocode({\"state\": row['State'], \"country\": \"USA\"})\n",
        "            if location:\n",
        "                point = Point(location.longitude, location.latitude)\n",
        "                geocode_cache[city_state] = point\n",
        "                return point\n",
        "            else:\n",
        "                print(f\"Location not found for state: {row['State']}\")\n",
        "                not_found_cache[city_state] = None\n",
        "                return None\n",
        "        else:\n",
        "            # Geocode using city and state\n",
        "            location = geolocator.geocode({\"city\": row['City'], \"state\": row['State'], \"country\": \"USA\"})\n",
        "            if location:\n",
        "                point = Point(location.longitude, location.latitude)\n",
        "                geocode_cache[city_state] = point\n",
        "                return point\n",
        "            else:\n",
        "                print(f\"Location not found: {city_state}\")\n",
        "                # Attempt to geocode using only state\n",
        "                location2 = geolocator.geocode({\"state\": row['State'], \"country\": \"USA\"})\n",
        "                if location2:\n",
        "                    point = Point(location2.longitude, location2.latitude)\n",
        "                    geocode_cache[city_state] = point\n",
        "                else:\n",
        "                    not_found_cache[city_state] = None\n",
        "                return None\n",
        "    except Exception as e:\n",
        "        print(f\"Geocoding error for {city_state}: {e}\")\n",
        "        time.sleep(1)  # Delay to handle rate limits\n",
        "        return None\n",
        "\n",
        "# Apply geocoding with a progress bar\n",
        "aggregated_df_pd = aggregated_df.toPandas()\n",
        "aggregated_df_pd['geometry'] = [geocode_location(row) for _, row in tqdm(aggregated_df_pd.iterrows(), total=len(aggregated_df_pd))]\n",
        "\n",
        "# Save cache for future use\n",
        "with open(cache_file, \"wb\") as f:\n",
        "    pickle.dump(geocode_cache, f)\n",
        "\n",
        "# Save not found cache for future reference\n",
        "not_found_cache_file = \"not_found_cache.pkl\"\n",
        "with open(not_found_cache_file, \"wb\") as f:\n",
        "    pickle.dump(not_found_cache, f)\n",
        "\n",
        "# Drop rows with missing geometry\n",
        "df = aggregated_df_pd.dropna(subset=['geometry'])\n",
        "\n",
        "# Create a GeoDataFrame\n",
        "gdf = gpd.GeoDataFrame(aggregated_df_pd, geometry='geometry', crs=\"EPSG:4326\")"
      ],
      "metadata": {
        "id": "CfXu5g_kkUlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e82403-1fb4-40dc-a922-5c15f0fa9786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 17/22798 [00:16<6:17:05,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Lexington-Fayette (corporate name for Lexington), Kentucky\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 52/22798 [00:52<6:15:38,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Vandenberg Air Force Base, California\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 67/22798 [01:08<6:20:50,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Indianapolis (Remainder), Indiana\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 71/22798 [01:13<7:01:25,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Calumet City (PU RR name Calumet Park (sta.)), Illinois\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 7793/22798 [02:46<00:44, 335.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location not found: Dentsville (Dents), South Carolina\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22798/22798 [02:55<00:00, 130.11it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.to_csv(\"pollution_data_spark_geocode.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "rZnDMH_8l52e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}